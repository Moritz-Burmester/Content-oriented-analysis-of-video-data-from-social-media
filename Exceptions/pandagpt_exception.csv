id,exception,Stacktrace
id_1102159051704672257_2019-03-03,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1103632030141689860_2019-03-07,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1106309828681650177_2019-03-14,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1107906875943612416_2019-03-19,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1110140673267851264_2019-03-25,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1111746540345929730_2019-03-29,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1112141580427816960_2019-03-30,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1112145353409740800_2019-03-31,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1112389232264396804_2019-03-31,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1112601796252442630_2019-04-01,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1112786990162997249_2019-04-01,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1112797734854160384_2019-04-01,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1112842018605162500_2019-04-01,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1113105104121618433_2019-04-02,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1113283568090873857_2019-04-03,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1113550023235702784_2019-04-03,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1113560360336994305_2019-04-03,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1113858984421875712_2019-04-04,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1113898273071411200_2019-04-04,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1113919219190644737_2019-04-04,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1114319437577052172_2019-04-06,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1114670250358972416_2019-04-06,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1115095700898029568_2019-04-08,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1113776549155807232_2019-04-09,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1116018088691097600_2019-04-10,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1118511946637217795_2019-04-17,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1145562690938638336_2019-07-01,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1146750661545140224_2019-07-04,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1147115571500204032_2019-07-05,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1147250045705699335_2019-07-05,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1148729822811570177_2019-07-09,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1148663087177904130_2019-07-10,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1148925481401688064_2019-07-10,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1149281337486036994_2019-07-11,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1150013822939422720_2019-07-13,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1150372883342024704_2019-07-14,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1151088272598286337_2019-07-16,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1151094540805332993_2019-07-16,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1151118969518137345_2019-07-16,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1151461072148324352_2019-07-17,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1153266859468308481_2019-07-22,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1153998183586062336_2019-07-24,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1154725369762783232_2019-07-26,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1155086040752893952_2019-07-27,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1155446729170460673_2019-07-28,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1155783795087425536_2019-07-29,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1156166696006225920_2019-07-30,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1156534917410578440_2019-07-31,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1168134390834171905_2019-09-01,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1169222982767714305_2019-09-04,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1170677404823695365_2019-09-08,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1170969474989776897_2019-09-09,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1171158164282068993_2019-09-09,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1171396716999954432_2019-09-10,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1171481281151954944_2019-09-10,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1171921604403744768_2019-09-11,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1172435684868517888_2019-09-13,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1172436036586049536_2019-09-13,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1172496407187664897_2019-09-13,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1173929696507154437_2019-09-17,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1174295672432058368_2019-09-18,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1174709416370851841_2019-09-19,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1174710035601137664_2019-09-19,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1174743725832056833_2019-09-19,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1175743995210797056_2019-09-22,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1176598948586426371_2019-09-24,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1176610415549263873_2019-09-24,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1178275755358334978_2019-09-29,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1190318864204271617_2019-11-01,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1190569618752061440_2019-11-02,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1190594356723490818_2019-11-02,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1190983318386413568_2019-11-03,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1192099035747885057_2019-11-06,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1192423374204653568_2019-11-07,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1193869225850556421_2019-11-11,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1194989626957668353_2019-11-14,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1196048608556191747_2019-11-17,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1196408025558462464_2019-11-18,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1196430014079815680_2019-11-18,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1197137497903501312_2019-11-20,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1197497544789708800_2019-11-21,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1197861550603866112_2019-11-22,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1197920438254493697_2019-11-22,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1198226408415354880_2019-11-23,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1198284956738310144_2019-11-23,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1197966535224123392_2019-11-24,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1198586897192407040_2019-11-24,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1198963606026625024_2019-11-25,[01:42:41] /github/workspace/src/runtime/ndarray.cc:171: Check failed: from_size == to_size (20736 vs. 15552) DECORDArrayCopyFromTo: The size must exactly match,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 357, in load_and_transform_video_data
    clip = video.get_clip(clip_timepoints[0], clip_timepoints[1])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/data/encoded_video_decord.py"", line 175, in get_clip
    raise e
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/data/encoded_video_decord.py"", line 172, in get_clip
    outputs = self._av_reader.get_batch(frame_idxs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/decord/video_reader.py"", line 175, in get_batch
    arr = _CAPI_VideoReaderGetBatch(self._handle, indices)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/decord/_ffi/_ctypes/function.py"", line 173, in __call__
    check_call(_LIB.DECORDFuncCall(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/decord/_ffi/base.py"", line 78, in check_call
    raise DECORDError(err_str)
decord._ffi.base.DECORDError: [01:42:41] /github/workspace/src/runtime/ndarray.cc:171: Check failed: from_size == to_size (20736 vs. 15552) DECORDArrayCopyFromTo: The size must exactly match
"
id_1199308229014106112_2019-11-26,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1199696811742638083_2019-11-27,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1200031041450369025_2019-11-28,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1200392490827866113_2019-11-29,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1200428055711358981_2019-11-29,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1200629181069086721_2019-11-30,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1213803919316373506_2020-01-05,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1235304307144241156_2020-03-04,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1235911736026443777_2020-03-06,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1236553738698948608_2020-03-08,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1236617319008305152_2020-03-08,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1236979240593248261_2020-03-09,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1238430369067732992_2020-03-13,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1238793910442475521_2020-03-14,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1239885721676251136_2020-03-17,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1240603556006309888_2020-03-19,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1240664739879010306_2020-03-19,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1240971441727823873_2020-03-20,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1241009025182924801_2020-03-20,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1241017100430446595_2020-03-20,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1240695010623922187_2020-03-21,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1242416621798465536_2020-03-24,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1243140736352161792_2020-03-26,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1243500610260996096_2020-03-27,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1244952710048333826_2020-03-31,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1245320795980812288_2020-04-01,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1245678552453918720_2020-04-02,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1246405847254740992_2020-04-04,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1246772830689165312_2020-04-05,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1247856820531744769_2020-04-08,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1247948609980526592_2020-04-08,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1248215134524170240_2020-04-09,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1249311176007303171_2020-04-12,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1250032253826146305_2020-04-14,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1250762665116471296_2020-04-16,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1251249236311769088_2020-04-17,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1252207608892723202_2020-04-20,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1253279675184529409_2020-04-23,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1253283978561425408_2020-04-23,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1254017239315030017_2020-04-25,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1254750339292704768_2020-04-27,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1255110118309531653_2020-04-28,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1256259653329203202_2020-05-01,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1256590836713885699_2020-05-02,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1256956902052974594_2020-05-03,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1257350585646546947_2020-05-04,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1258007294920421376_2020-05-06,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1258007819606884353_2020-05-06,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1258008549210247168_2020-05-06,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1258008822158745601_2020-05-06,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1258373303187705857_2020-05-07,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1258600511957327873_2020-05-08,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1258740323221680133_2020-05-08,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1260538848846786560_2020-05-13,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1260880007578161152_2020-05-14,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1260887763076943872_2020-05-14,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1261264186945961985_2020-05-15,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1261326960128454656_2020-05-15,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1261630117903769603_2020-05-16,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1261986666631348228_2020-05-17,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1263434335727878145_2020-05-21,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1263802096362586112_2020-05-22,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1264159493044264966_2020-05-23,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1264888008160968704_2020-05-25,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1265117970344431617_2020-05-26,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1266012602141999106_2020-05-28,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1266330660769353729_2020-05-29,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1266703756810485761_2020-05-30,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1267059050052751360_2020-05-31,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1267096241248309248_2020-05-31,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1267418346456264704_2020-06-01,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1267781572616429568_2020-06-02,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1267817311085326340_2020-06-02,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1268153936114003971_2020-06-03,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1268516657569452034_2020-06-04,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1268926808428285953_2020-06-05,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1269234800352800768_2020-06-06,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1269955789856354305_2020-06-08,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1270315544319856640_2020-06-09,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1271052736197529600_2020-06-11,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1271417775202975748_2020-06-12,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1272863059405615106_2020-06-16,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1273223791473238016_2020-06-17,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1273586329964761089_2020-06-18,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1273947322939052034_2020-06-19,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1274306863115444225_2020-06-20,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1274712879242129408_2020-06-21,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1275033811701694465_2020-06-22,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1275395509730099200_2020-06-23,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1275860878391476225_2020-06-24,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1276850322179227648_2020-06-27,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1277210344994283520_2020-06-28,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1277578499713368068_2020-06-29,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1277932831054934016_2020-06-30,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1278301504764612609_2020-07-01,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1278302619971342341_2020-07-01,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1278681454311022592_2020-07-02,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1279024977719820290_2020-07-03,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1279382827553959938_2020-07-04,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1279920537138081792_2020-07-05,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1279074228826976256_2020-07-06,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1280491367677022208_2020-07-07,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1280836971913510912_2020-07-08,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1281198312851464193_2020-07-09,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1281499715364888577_2020-07-10,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1281559230521184257_2020-07-10,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1282285737963065344_2020-07-12,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1282641426774405120_2020-07-13,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1283384142219087873_2020-07-15,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1284103346455019522_2020-07-17,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1284466142485020675_2020-07-18,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1286573126176964608_2020-07-24,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1286630401721675776_2020-07-24,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1286991845575340032_2020-07-25,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1288446269518680064_2020-07-29,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1288871815339741185_2020-07-30,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1289170273321787392_2020-07-31,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1301128408898973698_2020-09-02,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1301136616958943234_2020-09-02,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1301860028153057280_2020-09-04,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1302234048086061058_2020-09-05,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1302568331321499648_2020-09-06,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1302868286053507072_2020-09-07,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1304381953584529410_2020-09-11,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1305948302911983616_2020-09-15,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1306557607411408897_2020-09-17,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1306923746360516612_2020-09-18,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1307285490547273732_2020-09-19,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1308037079348269058_2020-09-21,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1308049251159728133_2020-09-21,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1308373749520007168_2020-09-22,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1308517506433380359_2020-09-22,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1309104654752657409_2020-09-24,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1309818415490752512_2020-09-26,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1310908564282761216_2020-09-29,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1311272573699842049_2020-09-30,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1324109886007975938_2020-11-04,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1324333925607612416_2020-11-05,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1324725739237920769_2020-11-06,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1325540346986713089_2020-11-08,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1325571824369995778_2020-11-09,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1325924804042559490_2020-11-10,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1326179736809320452_2020-11-10,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1326876178683207680_2020-11-12,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1327262600636338178_2020-11-13,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1328052931279675393_2020-11-15,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1328315713350737922_2020-11-16,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1328356010533277696_2020-11-16,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1329397870710169601_2020-11-19,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1329406389064785921_2020-11-19,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1329756559472259076_2020-11-20,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1330118916736167940_2020-11-21,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1331043621789978633_2020-11-24,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1331153132714397696_2020-11-24,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1331320991629283328_2020-11-24,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1331942280069050368_2020-11-26,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1333191543029690371_2020-11-29,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1333404039992709121_2020-11-30,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1333338647119196160_2020-12-01,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1333754814841413632_2020-12-01,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1335569986253893634_2020-12-06,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1336717336070541314_2020-12-09,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1336723684879429638_2020-12-09,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1337020253059108866_2020-12-10,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1338107063063470083_2020-12-13,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1338370697928781825_2020-12-14,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1338826613878878214_2020-12-15,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1339205628154302467_2020-12-16,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1339708902770761729_2020-12-17,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1341033652260630529_2020-12-21,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1341728871729815552_2020-12-23,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1342453750359871488_2020-12-25,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1343751690936266752_2020-12-29,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1343907538853638145_2020-12-29,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1344707820550295553_2020-12-31,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1366384390239059969_2021-03-01,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1367757797878861825_2021-03-05,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1368550554067156992_2021-03-07,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1368839410620375045_2021-03-08,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1368910166591234048_2021-03-08,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1369629295027576836_2021-03-10,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1370087374957477898_2021-03-11,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1370378014744317954_2021-03-12,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1370712675890647040_2021-03-13,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1371249881956896771_2021-03-15,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1371435361319129088_2021-03-15,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1371442265344868352_2021-03-15,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1371525250215731201_2021-03-15,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1371659935658872832_2021-03-16,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1372109675479625731_2021-03-17,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1372883779497381898_2021-03-19,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1373707640791040003_2021-03-21,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1374698128524386306_2021-03-24,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1375371161530404865_2021-03-26,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1375463820374781955_2021-03-26,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1375822719237943298_2021-03-27,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1375863953243377669_2021-03-27,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1376235806516506626_2021-03-28,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1376632786392612871_2021-03-29,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1377033508552577026_2021-03-30,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1377231278991409154_2021-03-31,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1377239662230573059_2021-03-31,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1377670982677245965_2021-04-02,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1378305981961146368_2021-04-03,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1378538880132059136_2021-04-04,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1379198313174593537_2021-04-05,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1379483852134027269_2021-04-06,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1379668795762094080_2021-04-08,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1380232378224902154_2021-04-08,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1380955852803354624_2021-04-10,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1382371006090727424_2021-04-14,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1382604584753975296_2021-04-15,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1382762764276531200_2021-04-15,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1383242966865637378_2021-04-17,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1383117672532041730_2021-04-18,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1384203099091259402_2021-04-19,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1384206461484507143_2021-04-19,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1384207569917386752_2021-04-19,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1384913409330843651_2021-04-21,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1384960537897938946_2021-04-21,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1385304246472437762_2021-04-22,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1386026602488860675_2021-04-24,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1386689261823483912_2021-04-26,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1386700390587056132_2021-04-26,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1386754648351117314_2021-04-26,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1387098026439843846_2021-04-27,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1387777445982572553_2021-04-29,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1387781521977888775_2021-04-29,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1387981107459670018_2021-04-30,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1388111851175780353_2021-04-30,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1388373186039984128_2021-05-01,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1388461294014156804_2021-05-01,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1388928490058260488_2021-05-02,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1389186519257202689_2021-05-03,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1389908800463908870_2021-05-05,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1390124371289772033_2021-05-06,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1390490845498023937_2021-05-07,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1390566276507054081_2021-05-08,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1391215568959721472_2021-05-09,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1392086575425769472_2021-05-11,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1392096686458216449_2021-05-11,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1392445400121057286_2021-05-12,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1393193492634083328_2021-05-14,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1393228958196449284_2021-05-14,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1394409754588553221_2021-05-17,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1394557025804328976_2021-05-18,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1394624244013752323_2021-05-18,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1395208068946964488_2021-05-20,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1395348615875514374_2021-05-20,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1395924336423415811_2021-05-22,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1396176431122681858_2021-05-22,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1396487444602699779_2021-05-23,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1397934282077720581_2021-05-27,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1397969370706583556_2021-05-27,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1398267876289781760_2021-05-28,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1398461223470080001_2021-05-29,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1399185313130549249_2021-05-31,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1399629336563666944_2021-06-01,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1399677929467125760_2021-06-01,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1400312496427261954_2021-06-03,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1401212186572251136_2021-06-05,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1401538225026523147_2021-06-06,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1401939536737882119_2021-06-07,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1402288044712120331_2021-06-08,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1402670232192290825_2021-06-09,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1403028278374457344_2021-06-10,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1403259961963077633_2021-06-11,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1403339057724276736_2021-06-11,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1403681535589502981_2021-06-12,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1404217428591222786_2021-06-13,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1404471203633508356_2021-06-14,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1404704991550623747_2021-06-15,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1405221914096771074_2021-06-16,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1405945626362269697_2021-06-18,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1406825268359184386_2021-06-21,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1406960356732424204_2021-06-21,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1409069992142774273_2021-06-27,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1409590341582344204_2021-06-28,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1409798279655723010_2021-06-29,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1410180364346265603_2021-06-30,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1410901332152795139_2021-07-02,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1412151339552055297_2021-07-05,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1412460635699482625_2021-07-06,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1412859858815270912_2021-07-07,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1412886445027741701_2021-07-07,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1413210674893709312_2021-07-08,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1414495238933159936_2021-07-12,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1414629156814352390_2021-07-12,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1414635417442439169_2021-07-12,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1415011203500417033_2021-07-13,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1415091266795282438_2021-07-13,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1415665938020454404_2021-07-15,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1415670591361720320_2021-07-15,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1415847513744084993_2021-07-16,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1416120997279830028_2021-07-16,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1416447436055355396_2021-07-17,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1417449436263948318_2021-07-20,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1417539226552446978_2021-07-20,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1418149120808718338_2021-07-22,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1418278090506215424_2021-07-22,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1418626756777553921_2021-07-23,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1419640970275131392_2021-07-26,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1420260835566374912_2021-07-28,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1420293180843446274_2021-07-28,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1420459484804177927_2021-07-28,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1433033972842389507_2021-09-01,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1433896088340160512_2021-09-05,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1435279077380866054_2021-09-07,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1435921790094741511_2021-09-09,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1436673608596688897_2021-09-11,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1438132095629545480_2021-09-15,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1438837509396602882_2021-09-17,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1440291214729744387_2021-09-21,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1440647888564932609_2021-09-22,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1441085890856579081_2021-09-24,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1442113099146743810_2021-09-26,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1442956762814959621_2021-09-28,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1443484848337920002_2021-09-30,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1443636317473189888_2021-09-30,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1455476686145789952_2021-11-02,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1455939360189149186_2021-11-03,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1456019623120306184_2021-11-03,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1457319622135402499_2021-11-07,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1457785369814978571_2021-11-08,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1457718553151410176_2021-11-10,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1458444151612137472_2021-11-10,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1458462966920089604_2021-11-10,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1458482101242716179_2021-11-10,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1458493157910335493_2021-11-10,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1458531160984850434_2021-11-10,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1459227591815090179_2021-11-12,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1459504684507582464_2021-11-13,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1459612523108265985_2021-11-13,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1459664123151663105_2021-11-13,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1459779483796389892_2021-11-14,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1460222757908594694_2021-11-15,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1460910229374308362_2021-11-17,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1461243064328998913_2021-11-18,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1461771957796548624_2021-11-19,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1462430431488393231_2021-11-21,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1463398382307790850_2021-11-24,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1464198771013828618_2021-11-26,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1464203848441286656_2021-11-26,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1464215344944455711_2021-11-26,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1464497480301793283_2021-11-27,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1464916211599302657_2021-11-28,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1467104123552251906_2021-12-04,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1467403539215536129_2021-12-05,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1468248703563870209_2021-12-07,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1470413256980320257_2021-12-13,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1471931310851637252_2021-12-17,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1473991415076167686_2021-12-23,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1474359726959955970_2021-12-24,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1478073223069810693_2022-01-03,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1478471711926460421_2022-01-04,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1478801881824641036_2022-01-05,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1479379212654059523_2022-01-07,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1480015890334822403_2022-01-09,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1480885615159824386_2022-01-11,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1481666077994192903_2022-01-13,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1482389417864093699_2022-01-15,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1483415640580964355_2022-01-18,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1484147270077591554_2022-01-20,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1484516696274706434_2022-01-21,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1485886519856533513_2022-01-25,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1486337779009310726_2022-01-26,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1488182109806432257_2022-01-31,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1488204771324739585_2022-01-31,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1487280655314481155_2022-02-02,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1488190276803964930_2022-02-02,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1488851912699129862_2022-02-02,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1488852468943540224_2022-02-02,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1490449844745478144_2022-02-06,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
id_1490958580148756483_2022-02-08,,"Traceback (most recent call last):
  File ""/work/mburmest/bachelorarbeit/main.py"", line 175, in classify_model
    results = classify(video, first_prompts, *args)
  File ""/work/mburmest/bachelorarbeit/classification_pandagpt.py"", line 54, in classify_pandagpt
    response = model.generate({
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 279, in generate
    input_embeds = self.prepare_generation_embedding(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 245, in prepare_generation_embedding
    feature_embeds = self.extract_multimodal_feature(inputs)
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 231, in extract_multimodal_feature
    video_embeds, _ = self.encode_video(inputs['video_paths'])
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/openllama.py"", line 121, in encode_video
    inputs = {ModalityType.VISION: data.load_and_transform_video_data(video_paths, self.device)}
  File ""/work/mburmest/bachelorarbeit/PandaGPT/code/model/ImageBind/data.py"", line 360, in load_and_transform_video_data
    video_clip = frame_sampler(clip[""video""])
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/transforms.py"", line 74, in forward
    return pytorchvideo.transforms.functional.uniform_temporal_subsample(
  File ""/home/mburmest/miniconda3/envs/pandagpt/lib/python3.8/site-packages/pytorchvideo/transforms/functional.py"", line 37, in uniform_temporal_subsample
    assert num_samples > 0 and t > 0
AssertionError
"
